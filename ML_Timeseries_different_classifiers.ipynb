{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_rows = 330\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(participants_to_include=0, split='within', window=12):\n",
    "        \n",
    "    \n",
    "    data = pd.read_pickle('Preprocessed_2021-03-15.pkl')\n",
    "\n",
    "    pilot_participants = ['gv_m_26','js_m_27','mb_f_30','tt_m_23', 'ys_m_29.1']\n",
    "    experiment_participants = ['al_m_23','bd_f_25','el_m_26','gh_m_29','lb_f_19',\\\n",
    "                               'mb_f_28','om_m_31','rl_f_24',\\\n",
    "                               'rt_f_21','sf_m_24','ts_f_26',]\n",
    "\n",
    "    participants = pilot_participants\n",
    "    participants+=experiment_participants\n",
    "\n",
    "    eeg_cols = []\n",
    "    eeg_cols += [\"baf_\"+str(x) for x in [*range(1,122)]]\n",
    "    eeg_cols += [\"tf_\"+str(x) for x in [*range(1,104)]]\n",
    "    eeg_cols += [\"VC_\"+str(x) for x in [*range(0,13)]]\n",
    "    eeg_cols += [\"A_\"+str(x) for x in [*range(0,14)]]\n",
    "    \n",
    "#     participants\n",
    "    df = data[data['participant']==participants[participants_to_include]]\n",
    "#     df = data\n",
    "#     X_a = np.array(data.loc[:,eeg_cols])\n",
    "#     print(X_a.shape)\n",
    "\n",
    "\n",
    "    \n",
    "#     y_a = np.array(data['participant'])\n",
    "#     print(y_a.shape)\n",
    "    \n",
    "    \n",
    "    # The EEG data is a matrix of 1673 rows and 251 columns. Need to reshape to 144 x WINDOW x 251\n",
    "    # then we can crop it down\n",
    "    loaded = list()\n",
    "    y = list()\n",
    "\n",
    "    for a in df.uniqueTrialCounter.unique(): #runs from 0 to 143\n",
    "        #load x element\n",
    "        b = np.array(data.loc[data.uniqueTrialCounter == a,'baf_1':'A_13'])[:window,:]\n",
    "        loaded.append(b)\n",
    "        #load y element\n",
    "        myindex = data[data['uniqueTrialCounter']==a].index[0]\n",
    "        y.append(data.iloc[myindex]['label'])\n",
    "\n",
    "    loaded = keras.preprocessing.sequence.pad_sequences(loaded, dtype=\"float\",)\n",
    "    loaded = np.stack(loaded)\n",
    "    print(loaded.shape)\n",
    "    X = loaded\n",
    "\n",
    "    y = np.array(y)\n",
    "    \n",
    "    print(y.shape)\n",
    "    y = y.reshape(len(y),1)\n",
    "    y.shape\n",
    "#     y = \n",
    "    \n",
    "    print(2*y.shape[0]//3)\n",
    "    \n",
    "    # np.max(X)\n",
    "#     normalizer = Normalization(axis=-1)\n",
    "#     normalizer.adapt(X)\n",
    "    \n",
    "#     Xn = normalizer(X)\n",
    "    \n",
    "    trainX = X[0:2*y.shape[0]//3]/np.max(X)\n",
    "    testX = X[2*y.shape[0]//3:]/np.max(X)\n",
    "    trainy = y[0:2*y.shape[0]//3]\n",
    "    testy = y[2*y.shape[0]//3:]\n",
    "\n",
    "    \n",
    "    mean = trainX.mean(axis=0)\n",
    "    std = trainX.std(axis=0)\n",
    "    trainX -= mean\n",
    "    trainX /=std\n",
    "    \n",
    "    testX -= mean\n",
    "    testX /=std\n",
    "#     trainy=to_categorical(trainy)\n",
    "#     testy=to_categorical(testy)\n",
    "    # zero-offset class values\n",
    "#     trainy = trainy - 1\n",
    "#     testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    \n",
    "\n",
    "    print(trainX.shape, trainy.shape, testX.shape, trainy.shape)\n",
    "    \n",
    "    return(trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateModel1(n_timesteps, n_features,n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100,  input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def generateModel2(n_timesteps, n_features,n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(n_timesteps ,n_features)))\n",
    "# #     model.add(LSTM(100))\n",
    "    model.add(Dropout(0.2))\n",
    "#     model.add(LSTM(100))\n",
    "#     model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = np.mean(scores), np.std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 9, 251)\n",
      "(144,)\n",
      "96\n",
      "(96, 9, 251) (96, 3) (48, 9, 251) (96, 3)\n",
      "9 251 3\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 6ms/step - loss: 1.1755 - accuracy: 0.2729\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9813 - accuracy: 0.5604\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9447 - accuracy: 0.6028\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8624 - accuracy: 0.7306\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7635 - accuracy: 0.7688\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7176 - accuracy: 0.8049\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6276 - accuracy: 0.8694\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5770 - accuracy: 0.8465\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5648 - accuracy: 0.8257\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.8306\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.9472\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3336 - accuracy: 0.9778\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3059 - accuracy: 0.9319\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2506 - accuracy: 0.9424\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2395 - accuracy: 0.9674\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1611 - accuracy: 0.9875\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1272 - accuracy: 0.9917\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1013 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0813 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.9861\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0638 - accuracy: 0.9875\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0447 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0491 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0466 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0335 - accuracy: 0.9917\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0459 - accuracy: 0.9792\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f254e0dfd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ">#1: 33.333\n",
      "(144, 9, 251)\n",
      "(144,)\n",
      "96\n",
      "(96, 9, 251) (96, 3) (48, 9, 251) (96, 3)\n",
      "9 251 3\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 8ms/step - loss: 1.1563 - accuracy: 0.2910\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0596 - accuracy: 0.3437\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9328 - accuracy: 0.6236\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8223 - accuracy: 0.6986\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7832 - accuracy: 0.7292\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6725 - accuracy: 0.7882\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5821 - accuracy: 0.8375\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5975 - accuracy: 0.8208\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5189 - accuracy: 0.8222\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.9194\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3005 - accuracy: 0.9674\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2917 - accuracy: 0.9792\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2307 - accuracy: 0.9556\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2134 - accuracy: 0.9965\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1219 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1406 - accuracy: 0.9840\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1004 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0875 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0754 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0688 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9965\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0186 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0274 - accuracy: 0.9965\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f283a416f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      ">#2: 35.417\n",
      "[33.33333432674408, 35.41666567325592]\n",
      "Accuracy: 34.375% (+/-1.042)\n"
     ]
    }
   ],
   "source": [
    "repeats=2\n",
    "# repeat experiment\n",
    "scores = list()\n",
    "for r in range(repeats):\n",
    "    # load data\n",
    "    trainX, trainy, testX, testy = get_data(0, 'within', 9)\n",
    "    \n",
    "    verbose, epochs, batch_size = 1, 50, 20\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    print(n_timesteps, n_features, n_outputs)\n",
    "    model = generateModel1(n_timesteps ,n_features, n_outputs)\n",
    " \n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, score = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    score = score * 100.0\n",
    "    print('>#%d: %.3f' % (r+1, score))\n",
    "    scores.append(score)\n",
    "    # summarize results\n",
    "summarize_results(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 251), dtype=float32, numpy=\n",
       "array([[ 0.40519565,  0.26390797,  0.2655608 , ...,  0.119133  ,\n",
       "         0.13291448,  0.41024023],\n",
       "       [ 0.39556843,  0.26244253,  0.20430121, ..., -0.07544658,\n",
       "         0.1272642 ,  0.3301033 ],\n",
       "       [ 0.3535288 , -0.1323592 , -0.18463203, ...,  0.06584046,\n",
       "        -0.00892712, -0.12109778],\n",
       "       [ 0.21057819, -0.1419756 , -0.04721254, ...,  0.03034545,\n",
       "        -0.02410885,  0.0777398 ],\n",
       "       [-0.02604828, -0.18671046,  0.01773684, ..., -0.13395451,\n",
       "        -0.08709727,  0.07572434],\n",
       "       [ 0.06540973, -0.0554717 ,  0.1254056 , ..., -0.07783575,\n",
       "        -0.10648037,  0.11190312]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX[0]\n",
    "# model.predict((testX[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
